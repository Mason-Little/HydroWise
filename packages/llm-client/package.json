{
  "name": "@hydrowise/llm-client",
  "version": "0.0.0",
  "private": true,
  "type": "module",
  "main": "./dist/index.js",
  "module": "./dist/index.js",
  "types": "./dist/index.d.ts",
  "scripts": {
    "build": "vite build",
    "clean": "rm -rf dist",
    "lint": "biome lint .",
    "format": "biome format . --write",
    "check": "biome check .",

    "llm": "../../tools/llama-b7876/llama-server -m ../../tools/models/qwen2.5-7b-instruct-q4_k_m.gguf --port 8080 --ctx-size 4096 -ngl 99 --parallel 2",
    "embeddings": "../../tools/llama-b7876/llama-server -m ../../tools/models/nomic-embed-text-v1.5.Q4_0.gguf --port 8081 --embeddings --pooling mean -ngl 99",
    "ocr": "../../tools/llama-b7876/llama-server -m ../../tools/models/LightOnOCR-2-1B-Q4_K_M.gguf --mmproj ../../tools/models/LightOnOCR-2-1B-mmproj-f16.gguf --port 8082 --ctx-size 4096 -ngl 99",
    "dev:desktop": "bun run llm & bun run embeddings & bun run ocr & wait",
    "dev:desktop:all": "bun run llm & bun run embeddings & bun run ocr & wait"
  },
  "dependencies": {
    "@ai-sdk/openai": "^3.0.24",
    "@browser-ai/transformers-js": "^2.0.2",
    "@browser-ai/web-llm": "^2.0.3",
    "@huggingface/transformers": "^3.8.1",
    "@mlc-ai/web-llm": "^0.2.79",
    "ai": "^6.0.66"
  },
  "exports": {
    ".": {
      "types": "./dist/index.d.ts",
      "import": "./dist/index.js",
      "require": "./dist/index.cjs"
    }
  },
  "devDependencies": {
    "vite": "^7.2.4",
    "vite-plugin-dts": "^4.5.4"
  }
}
